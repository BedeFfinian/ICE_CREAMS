{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Intertidal Classification of Europe: Categorising Reflectance of Emerged Areas of Marine vegetation using Sentinel 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICE CREAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import fastbook module and required elements within it to run a tabular learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in training data in wide format.\n",
    "Each version of the model is stored in a separate folder inside Data/Input/Training of the repository. csv files have also been separated into 100,000 row files to minimise file sizes. Therefore, we need to combine them all to create the full training dataframe. \n",
    "\n",
    "Training data for ICE CREAMS has 26 features and one label/y column with 9 classes. Features are 12 Bottom of Atmosphere reflectance columns, 12 Min-Max standardised reflectance columns, and 2 columns for Normalised Difference Vegetation Index (NDVI) and Normalised Difference Water Index (NDWI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Location_V1_1=glob.glob(\"Data/Input/Training/V1_1/*.csv\")\n",
    "Training_Location_V1_2=glob.glob(\"Data/Input/Training/V1_2/*.csv\")\n",
    "Training_Location_V1_3=glob.glob(\"Data/Input/Training/V1_3/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_df_V1_1 = pd.concat((pd.read_csv(f) for f in Training_Location_V1_1), ignore_index=True)\n",
    "Training_df_V1_2 = pd.concat((pd.read_csv(f) for f in Training_Location_V1_2), ignore_index=True)\n",
    "Training_df_V1_3 = pd.concat((pd.read_csv(f) for f in Training_Location_V1_3), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_nn = pd.concat([Training_df_V1_1,Training_df_V1_2,Training_df_V1_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labelled column is called True_Class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = \"True_Class\"\n",
    "splits = RandomSplitter()(df_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select which columns are categoric and which are continuous, ICE CREAMS uses just continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_nn,cat_nn = cont_cat_split(df_nn, dep_var=dep_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal pre processing is carried out but if any missing data is present it should be filled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs_nn = [FillMissing]\n",
    "to_nn = TabularPandas(df_nn, procs_nn, cat_nn, cont_nn,\n",
    "                      splits=splits, y_names=dep_var, y_block=CategoryBlock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls = to_nn.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_nn.train.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleate the learner, which is a tabular learner with 9 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls,n_out=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune the learner/model over 20 epochs. Default fine tuning is carried out with ADAM optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.117107</td>\n",
       "      <td>0.089233</td>\n",
       "      <td>05:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.078566</td>\n",
       "      <td>0.075846</td>\n",
       "      <td>05:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.090137</td>\n",
       "      <td>0.082894</td>\n",
       "      <td>04:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.082426</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>06:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088419</td>\n",
       "      <td>0.076407</td>\n",
       "      <td>04:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087824</td>\n",
       "      <td>0.081293</td>\n",
       "      <td>04:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086214</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>03:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.086931</td>\n",
       "      <td>0.073443</td>\n",
       "      <td>04:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084105</td>\n",
       "      <td>0.077795</td>\n",
       "      <td>04:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074703</td>\n",
       "      <td>0.071271</td>\n",
       "      <td>04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075947</td>\n",
       "      <td>0.068997</td>\n",
       "      <td>04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.081363</td>\n",
       "      <td>0.067819</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.070040</td>\n",
       "      <td>0.075828</td>\n",
       "      <td>09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065266</td>\n",
       "      <td>0.076520</td>\n",
       "      <td>12:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.073680</td>\n",
       "      <td>0.067662</td>\n",
       "      <td>09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070255</td>\n",
       "      <td>0.063255</td>\n",
       "      <td>05:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.069613</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>04:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.061984</td>\n",
       "      <td>0.059864</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.066464</td>\n",
       "      <td>0.056989</td>\n",
       "      <td>04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.057199</td>\n",
       "      <td>0.061159</td>\n",
       "      <td>04:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.055563</td>\n",
       "      <td>0.061739</td>\n",
       "      <td>04:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the Pickled Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.export('ICECREAMS_V1_3.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
